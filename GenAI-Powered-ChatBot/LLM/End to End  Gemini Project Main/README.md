# ğŸ’¬ TinyLLaMA Chatbot â€“ Final Year Project

This project is a **locally running GenAI-powered chatbot** built using **LangChain**, **Ollama**, and **Streamlit**, powered by the lightweight `tinyllama` model for efficient offline conversational AI.

Developed by **Vineet Sharma (LNMIIT)** (May 2025 â€“ June 2025).  
Email: vneetsharma01@gmail.com

---

## ğŸš€ Features

- ğŸ” Memory-enabled conversation
- ğŸ’¾ Chat download option
- ğŸ¨ Stylish chat interface
- ğŸ§  Powered by TinyLLaMA (local LLM)
- ğŸ—‘ï¸ Clear chat history
- ğŸ“ Offline and open-source

---

## ğŸ› ï¸ Installation

### 1. Clone this repository

```bash
git clone https://github.com/Vineet012004/tinyllama_chatbot.git
```

### 2. Navigate into the project folder

```bash
cd tinyllama_chatbot
```

### 3. Install required Python dependencies

```bash
pip install -r requirements.txt
```

> Make sure you have Python â‰¥ 3.8 installed and activated in your environment.

### 4. Pull the TinyLLaMA model using Ollama

```bash
ollama pull tinyllama
```

---

## ğŸ’¡ Usage

Start the chatbot using:

```bash
streamlit run app.py
```

- The chatbot will open in your default browser at:  
  `http://localhost:8501`

- Type your message in the input box.

- You can clear the conversation or download it as `.txt`.

---

## ğŸ§  Requirements

Make sure you have these installed:

- `ollama`
- `Python 3.8+`
- `Streamlit`
- `LangChain`
- `tinyllama` model (automatically downloaded via `ollama pull`)

---

## ğŸ“‚ Folder Structure

```
tinyllama_chatbot/
â”œâ”€â”€ app.py                 # Main Streamlit chatbot script
â”œâ”€â”€ requirements.txt       # Required Python libraries
â””â”€â”€ README.md              # This file
```

---

## ğŸ“¢ Creator Info

ğŸ‘¨â€ğŸ’» Created by: **Vineet Sharma (LNMIIT)**  
ğŸ“§ Email: vneetsharma01@gmail.com  
ğŸ“… Duration: May 2025 â€“ June 2025
